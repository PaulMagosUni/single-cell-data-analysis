{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'kumar-8-hard'\n",
    "data_path = \"./dataset/{}-filtered/10X/\".format(dataset)\n",
    "labels_path = \"./dataset/{}-filtered/labels.csv\".format(dataset)\n",
    "markers_path = \"./results/aggregate/{}/markers.csv\".format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\n",
    "    data_path,\n",
    "    var_names='gene_symbols',\n",
    "    cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.read_csv(labels_path, index_col=0)\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(adata.obs_names, columns=[\"cell\"]).join(y_df, on=\"cell\")\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~np.isnan(np.array(y_df['cluster.ids'])).reshape(-1)\n",
    "mask[mask==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df['cluster.ids'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_df['cluster.ids'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, counts = np.unique(y, return_counts=True)\n",
    "clusters, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = counts[np.argsort(clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classifier(X, y):\n",
    "    clf = RandomForestClassifier()\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=5)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return f1\n",
    "\n",
    "markers_df = pd.read_csv(markers_path)\n",
    "tools = markers_df.tool.unique()\n",
    "\n",
    "f1_markers = {}\n",
    "for tool in tools:\n",
    "    f1_markers_tool = []\n",
    "    for cluster in clusters:\n",
    "        y_bin = np.array(y==cluster, dtype=int)\n",
    "        markers = markers_df[\n",
    "            (markers_df['cluster']==cluster) & (markers_df['tool']==tool)\n",
    "           ].gene.unique()\n",
    "        X_markers = adata[mask, markers].X.toarray()\n",
    "        f1_markers_tool.append(apply_classifier(X_markers, y_bin))\n",
    "    f1_markers[tool] = round((weights*np.array(f1_markers_tool)).sum()/weights.sum(), 3)\n",
    "\n",
    "f1_all = []\n",
    "for cluster in clusters:\n",
    "    y_bin = np.array(y==cluster, dtype=int)\n",
    "    X_all = adata[mask, ].X.toarray()\n",
    "    f1_all.append(apply_classifier(X_all, y_bin))\n",
    "f1_weighted = round((weights*np.array(f1_all)).sum()/weights.sum(), 3)\n",
    "\n",
    "print(\"F1 weighted when training on markers\")\n",
    "print(f1_markers)\n",
    "print(\"F1 weighted when training on all genes\")\n",
    "print(f1_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool:  scvi\n",
      "Cluster:  1\n",
      "Cluster:  2\n",
      "Cluster:  3\n",
      "Cluster:  4\n",
      "Cluster:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scvi': {1: {'scores': [0.819277108433735,\n",
       "    0.8670520231213872,\n",
       "    0.898876404494382,\n",
       "    0.898876404494382,\n",
       "    0.9050279329608939,\n",
       "    0.893854748603352,\n",
       "    0.8876404494382023,\n",
       "    0.8876404494382023,\n",
       "    0.8729281767955801,\n",
       "    0.8633879781420767],\n",
       "   'mean': [0.8794561675922192]},\n",
       "  2: {'scores': [0.9666666666666667,\n",
       "    0.9833333333333333,\n",
       "    0.9836065573770492,\n",
       "    0.9917355371900827,\n",
       "    0.9917355371900827,\n",
       "    0.9917355371900827,\n",
       "    0.9917355371900827,\n",
       "    0.9833333333333333,\n",
       "    0.9917355371900827,\n",
       "    0.9833333333333333],\n",
       "   'mean': [0.9858950909994129]},\n",
       "  3: {'scores': [0.9838709677419355,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561,\n",
       "    0.975609756097561],\n",
       "   'mean': [0.9764358772619985]},\n",
       "  4: {'scores': [0.9364161849710984,\n",
       "    0.9824561403508771,\n",
       "    0.9824561403508771,\n",
       "    0.9854227405247813,\n",
       "    0.9854227405247813,\n",
       "    0.9883720930232558,\n",
       "    0.991304347826087,\n",
       "    0.9883720930232558,\n",
       "    0.991304347826087,\n",
       "    0.9883720930232558],\n",
       "   'mean': [0.9819898921444355]},\n",
       "  5: {'scores': [0.9750566893424036,\n",
       "    0.9664429530201343,\n",
       "    0.9683257918552037,\n",
       "    0.9662921348314608,\n",
       "    0.9705215419501133,\n",
       "    0.9866071428571429,\n",
       "    0.9866071428571429,\n",
       "    0.9865470852017937,\n",
       "    0.988814317673378,\n",
       "    0.9865470852017937],\n",
       "   'mean': [0.9781761884790567]},\n",
       "  'TotalMean': [0.9396118242197339,\n",
       "   0.9576839930532023,\n",
       "   0.9634519372267307,\n",
       "   0.9643278224590667,\n",
       "   0.9668472169346177,\n",
       "   0.9717606314674869,\n",
       "   0.9715910147866155,\n",
       "   0.9699346241384056,\n",
       "   0.9700591049238534,\n",
       "   0.9660825298320517]}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------- train with increasing # of features taken from markers rank --------\n",
    "scores = {}\n",
    "step = 1\n",
    "tools = ['scvi', 'seurat', 'scanpy', 'monocle']\n",
    "for tool in tools:\n",
    "    print('Tool: ', tool)\n",
    "    for cluster in clusters:\n",
    "        print('Cluster: ', cluster)\n",
    "        n_markers = len(markers_df[markers_df['cluster']==cluster])   \n",
    "        y_bin = np.array(y==cluster, dtype=int)\n",
    "        for i in range(step, n_markers+step, step):\n",
    "            markers = markers_df[\n",
    "            (markers_df['cluster']==cluster) & (markers_df['tool']==tool) & (markers_df['rank']<=i)\n",
    "           ].gene.unique()\n",
    "            X = adata[mask, markers].X.toarray()\n",
    "            f1 = apply_classifier(X, y_bin)\n",
    "            if tool not in scores:\n",
    "                scores[tool] = {}\n",
    "            if cluster not in scores[tool]:\n",
    "                scores[tool][cluster] = {}\n",
    "            if 'scores' not in scores[tool][cluster]:\n",
    "                scores[tool][cluster]['scores'] = []\n",
    "            scores[tool][cluster]['scores'].append(f1)\n",
    "        if 'mean' not in scores[tool][cluster]:\n",
    "            scores[tool][cluster]['mean'] = []\n",
    "        # mean for each cluster\n",
    "        scores[tool][cluster]['mean'].append(np.mean(scores[tool][cluster]['scores']))\n",
    "\n",
    "for tool in tools:\n",
    "    for i in range(step, n_markers+step, step):\n",
    "        sumForI = 0\n",
    "        for j, cluster in enumerate(clusters):\n",
    "            sumForI += (scores[tool][cluster]['scores'][i-1] * counts[j])\n",
    "        if 'TotalMean' not in scores[tool]:\n",
    "            scores[tool]['TotalMean'] = []\n",
    "        scores[tool]['TotalMean'].append(sumForI/np.sum(counts))\n",
    "\n",
    "# x_ticks = [i for i in range(step, n_markers+step, step)]\n",
    "# # 4 axes plot\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# plt.xticks(x_ticks, x_ticks)\n",
    "# plt.plot(x_ticks, scores, marker='o')\n",
    "# plt.ylabel(\"f1 weighted\")\n",
    "# plt.xlabel(\"# top features from each tool\")\n",
    "# plt.grid()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig(out_path+\"score.eps\")\n",
    "\n",
    "# pd.DataFrame(scores, columns=['f1 weighted']).to_csv(out_path+\"clf_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9396118242197339,\n",
       " 0.9576839930532023,\n",
       " 0.9634519372267307,\n",
       " 0.9643278224590667,\n",
       " 0.9668472169346177,\n",
       " 0.9717606314674869,\n",
       " 0.9715910147866155,\n",
       " 0.9699346241384056,\n",
       " 0.9700591049238534,\n",
       " 0.9660825298320517]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['scvi']['TotalMean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- train on all features and on markers --------\n",
    "\n",
    "X_all = adata[mask, :].X.toarray()\n",
    "report_all, feature_importance = apply_classifier(X_all, y)\n",
    "report_markers, _ = apply_classifier(adata[mask, markers].X.toarray(), y)\n",
    "\n",
    "pd.DataFrame(report_all).transpose().to_csv(out_path+\"clf_report_all.csv\")\n",
    "pd.DataFrame(report_markers).transpose().to_csv(out_path+\"clf_report_markers.csv\")\n",
    "\n",
    "sorted_idx = (-feature_importance).argsort()\n",
    "rf_features_sorted = adata.var_names[sorted_idx]\n",
    "importaces_sorted = feature_importance[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rf_features_sorted, 'importaces' : importaces_sorted}\n",
    "    ).to_csv(out_path+\"importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- select n_markers*n_clusters features with RFE and RF --------\n",
    "\n",
    "selector = RFE(RandomForestClassifier(), n_features_to_select=n_markers*n_clusters, step=0.5)\n",
    "selector.fit(X_all, y)\n",
    "sorted_idx = (selector.ranking_).argsort()\n",
    "rfe_features_sorted = adata.var_names[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rfe_features_sorted}\n",
    "    ).to_csv(out_path+\"rfe_ranking.csv\")\n",
    "\n",
    "# automatically choose the number of features\n",
    "# rfe = RFECV(estimator=RandomForestClassifier())\n",
    "# rfe.fit(X_all, y)\n",
    "# rfe.show()\n",
    "\n",
    "# TODO:\n",
    "# - valutare intersezione\n",
    "# - valutare bontà del ranking allenando con markers più in basso nella classifica?\n",
    "\n",
    "# important_features = features_sorted[0:120]\n",
    "# important_features = [f for f, i in zip(features_sorted, importaces_sorted) if i >= importaces_sorted[119]]\n",
    "# intersection = set(markers).intersection(set(important_features))\n",
    "\n",
    "#        rank di randomforest                  rank del tool\n",
    "# gene1         100 *                         * 1 - (0-20)\n",
    "# gene2         1 *                            \n",
    "# gene3         1 *                            \n",
    "# gene4         0 *                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHLPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
