{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'kumar-8-hard'\n",
    "data_path = \"./dataset/{}-filtered/10X/\".format(dataset)\n",
    "labels_path = \"./dataset/{}-filtered/labels.csv\".format(dataset)\n",
    "markers_path = \"./results/aggregate/{}/markers.csv\".format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\n",
    "    data_path,\n",
    "    var_names='gene_symbols',\n",
    "    cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.read_csv(labels_path, index_col=0)\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(adata.obs_names, columns=[\"cell\"]).join(y_df, on=\"cell\")\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~np.isnan(np.array(y_df['cluster.ids'])).reshape(-1)\n",
    "mask[mask==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df['cluster.ids'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_df['cluster.ids'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, counts = np.unique(y, return_counts=True)\n",
    "clusters, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = counts[np.argsort(clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classifier(X, y):\n",
    "    clf = RandomForestClassifier()\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=5)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return f1\n",
    "\n",
    "markers_df = pd.read_csv(markers_path)\n",
    "tools = markers_df.tool.unique()\n",
    "\n",
    "f1_markers = {}\n",
    "for tool in tools:\n",
    "    f1_markers_tool = []\n",
    "    for cluster in clusters:\n",
    "        y_bin = np.array(y==cluster, dtype=int)\n",
    "        markers = markers_df[\n",
    "            (markers_df['cluster']==cluster) & (markers_df['tool']==tool)\n",
    "           ].gene.unique()\n",
    "        X_markers = adata[mask, markers].X.toarray()\n",
    "        f1_markers_tool.append(apply_classifier(X_markers, y_bin))\n",
    "    f1_markers[tool] = round((weights*np.array(f1_markers_tool)).sum()/weights.sum(), 3)\n",
    "\n",
    "f1_all = []\n",
    "for cluster in clusters:\n",
    "    y_bin = np.array(y==cluster, dtype=int)\n",
    "    X_all = adata[mask, ].X.toarray()\n",
    "    f1_all.append(apply_classifier(X_all, y_bin))\n",
    "f1_weighted = round((weights*np.array(f1_all)).sum()/weights.sum(), 3)\n",
    "\n",
    "print(\"F1 weighted when training on markers\")\n",
    "print(f1_markers)\n",
    "print(\"F1 weighted when training on all genes\")\n",
    "print(f1_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- train with increasing # of features taken from markers rank --------\n",
    "scores = {}\n",
    "step = 1\n",
    "tools = ['scvi', 'seurat', 'scanpy', 'monocle']\n",
    "\n",
    "import pickle, os\n",
    "if os.path.exists('scores_tabula-muris-heart.pickle'):\n",
    "    with open('scores_tabula-muris-heart.pickle', 'rb') as handle:\n",
    "        scores = pickle.load(handle)\n",
    "else:\n",
    "    for tool in tools:\n",
    "        print('Tool: ', tool)\n",
    "        for cluster in clusters:\n",
    "            print('Cluster: ', cluster)\n",
    "            n_markers = len(markers_df[markers_df['cluster']==cluster])   \n",
    "            y_bin = np.array(y==cluster, dtype=int)\n",
    "            for i in range(step, n_markers+step, step):\n",
    "                markers = markers_df[\n",
    "                (markers_df['cluster']==cluster) & (markers_df['tool']==tool) & (markers_df['rank']<=i)\n",
    "            ].gene.unique()\n",
    "                X = adata[mask, markers].X.toarray()\n",
    "                f1 = apply_classifier(X, y_bin)\n",
    "                if tool not in scores:\n",
    "                    scores[tool] = {}\n",
    "                if cluster not in scores[tool]:\n",
    "                    scores[tool][cluster] = {}\n",
    "                if 'scores' not in scores[tool][cluster]:\n",
    "                    scores[tool][cluster]['scores'] = []\n",
    "                scores[tool][cluster]['scores'].append(f1)\n",
    "            if 'mean' not in scores[tool][cluster]:\n",
    "                scores[tool][cluster]['mean'] = []\n",
    "            # mean for each cluster\n",
    "            scores[tool][cluster]['mean'].append(np.mean(scores[tool][cluster]['scores']))\n",
    "\n",
    "    for tool in tools:\n",
    "        for i in range(step, n_markers+step, step):\n",
    "            sumForI = 0\n",
    "            for j, cluster in enumerate(clusters):\n",
    "                sumForI += (scores[tool][cluster]['scores'][i-1] * counts[j])\n",
    "            if 'TotalMean' not in scores[tool]:\n",
    "                scores[tool]['TotalMean'] = []\n",
    "            scores[tool]['TotalMean'].append(sumForI/np.sum(counts))\n",
    "\n",
    "    with open('scores_tabula-muris-heart.pickle', 'wb') as handle:\n",
    "        pickle.dump(scores, handle, protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "\n",
    "# x_ticks = [i for i in range(step, n_markers+step, step)]\n",
    "# # 4 axes plot\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# plt.xticks(x_ticks, x_ticks)\n",
    "# plt.plot(x_ticks, scores, marker='o')\n",
    "# plt.ylabel(\"f1 weighted\")\n",
    "# plt.xlabel(\"# top features from each tool\")\n",
    "# plt.grid()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig(out_path+\"score.eps\")\n",
    "\n",
    "# pd.DataFrame(scores, columns=['f1 weighted']).to_csv(out_path+\"clf_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- train on all features and on markers --------\n",
    "\n",
    "X_all = adata[mask, :].X.toarray()\n",
    "report_all, feature_importance = apply_classifier(X_all, y)\n",
    "report_markers, _ = apply_classifier(adata[mask, markers].X.toarray(), y)\n",
    "\n",
    "pd.DataFrame(report_all).transpose().to_csv(out_path+\"clf_report_all.csv\")\n",
    "pd.DataFrame(report_markers).transpose().to_csv(out_path+\"clf_report_markers.csv\")\n",
    "\n",
    "sorted_idx = (-feature_importance).argsort()\n",
    "rf_features_sorted = adata.var_names[sorted_idx]\n",
    "importaces_sorted = feature_importance[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rf_features_sorted, 'importaces' : importaces_sorted}\n",
    "    ).to_csv(out_path+\"importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- select n_markers*n_clusters features with RFE and RF --------\n",
    "\n",
    "selector = RFE(RandomForestClassifier(), n_features_to_select=n_markers*n_clusters, step=0.5)\n",
    "selector.fit(X_all, y)\n",
    "sorted_idx = (selector.ranking_).argsort()\n",
    "rfe_features_sorted = adata.var_names[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rfe_features_sorted}\n",
    "    ).to_csv(out_path+\"rfe_ranking.csv\")\n",
    "\n",
    "# automatically choose the number of features\n",
    "# rfe = RFECV(estimator=RandomForestClassifier())\n",
    "# rfe.fit(X_all, y)\n",
    "# rfe.show()\n",
    "\n",
    "# TODO:\n",
    "# - valutare intersezione\n",
    "# - valutare bontà del ranking allenando con markers più in basso nella classifica?\n",
    "\n",
    "# important_features = features_sorted[0:120]\n",
    "# important_features = [f for f, i in zip(features_sorted, importaces_sorted) if i >= importaces_sorted[119]]\n",
    "# intersection = set(markers).intersection(set(important_features))\n",
    "\n",
    "#        rank di randomforest                  rank del tool\n",
    "# gene1         100 *                         * 1 - (0-20)\n",
    "# gene2         1 *                            \n",
    "# gene3         1 *                            \n",
    "# gene4         0 *                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHLPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
