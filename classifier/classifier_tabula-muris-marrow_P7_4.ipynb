{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'peipheal-blood'\n",
    "data_path = \"./dataset/{}-filtered/10X/\".format(dataset)\n",
    "labels_path = \"./dataset/{}-filtered/labels.csv\".format(dataset)\n",
    "markers_path = \"./results/aggregate/{}/markers.csv\".format(dataset)\n",
    "scores_path = \"./scores/{}.pickle\".format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\n",
    "    data_path,\n",
    "    var_names='gene_symbols',\n",
    "    cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster.ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cell1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell10</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell100</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell101</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell102</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell95</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell97</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell98</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell99</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cluster.ids\n",
       "cell                \n",
       "Cell1              4\n",
       "Cell10             2\n",
       "Cell100            3\n",
       "Cell101            2\n",
       "Cell102            3\n",
       "...              ...\n",
       "Cell95             3\n",
       "Cell96             1\n",
       "Cell97             3\n",
       "Cell98             2\n",
       "Cell99             4\n",
       "\n",
       "[499 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.read_csv(labels_path, index_col=0)\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>cluster.ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Cell496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Cell497</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Cell498</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Cell499</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Cell500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cell  cluster.ids\n",
       "0      Cell1            4\n",
       "1      Cell2            4\n",
       "2      Cell3            4\n",
       "3      Cell4            2\n",
       "4      Cell5            1\n",
       "..       ...          ...\n",
       "494  Cell496            3\n",
       "495  Cell497            3\n",
       "496  Cell498            3\n",
       "497  Cell499            4\n",
       "498  Cell500            1\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(adata.obs_names, columns=[\"cell\"]).join(y_df, on=\"cell\")\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ~np.isnan(np.array(y_df['cluster.ids'])).reshape(-1)\n",
    "mask[mask==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      4\n",
       "2      4\n",
       "3      2\n",
       "4      1\n",
       "      ..\n",
       "494    3\n",
       "495    3\n",
       "496    3\n",
       "497    4\n",
       "498    1\n",
       "Name: cluster.ids, Length: 499, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df['cluster.ids'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_df['cluster.ids'][mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([105,  61, 210, 123]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters, counts = np.unique(y, return_counts=True)\n",
    "clusters, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = counts[np.argsort(clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 weighted when training on markers\n",
      "{'monocle': 0.992, 'scanpy': 0.989, 'seurat': 0.989, 'scvi': 0.989}\n",
      "F1 weighted when training on all genes\n",
      "0.919\n"
     ]
    }
   ],
   "source": [
    "def apply_classifier(X, y):\n",
    "    clf = RandomForestClassifier()\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=5)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return f1\n",
    "\n",
    "markers_df = pd.read_csv(markers_path)\n",
    "tools = markers_df.tool.unique()\n",
    "\n",
    "f1_markers = {}\n",
    "for tool in tools:\n",
    "    f1_markers_tool = []\n",
    "    for cluster in clusters:\n",
    "        y_bin = np.array(y==cluster, dtype=int)\n",
    "        markers = markers_df[\n",
    "            (markers_df['cluster']==cluster) & (markers_df['tool']==tool)\n",
    "           ].gene.unique()\n",
    "        X_markers = adata[mask, markers].X.toarray()\n",
    "        f1_markers_tool.append(apply_classifier(X_markers, y_bin))\n",
    "    f1_markers[tool] = round((weights*np.array(f1_markers_tool)).sum()/weights.sum(), 3)\n",
    "\n",
    "f1_all = []\n",
    "for cluster in clusters:\n",
    "    y_bin = np.array(y==cluster, dtype=int)\n",
    "    X_all = adata[mask, ].X.toarray()\n",
    "    f1_all.append(apply_classifier(X_all, y_bin))\n",
    "f1_weighted = round((weights*np.array(f1_all)).sum()/weights.sum(), 3)\n",
    "\n",
    "print(\"F1 weighted when training on markers\")\n",
    "print(f1_markers)\n",
    "print(\"F1 weighted when training on all genes\")\n",
    "print(f1_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "def process(tool):\n",
    "    step = 1\n",
    "    tmp_scores = {}\n",
    "    for cluster in clusters:\n",
    "        n_markers = len(markers_df[markers_df['cluster']==cluster])   \n",
    "        y_bin = np.array(y==cluster, dtype=int)\n",
    "        for i in range(step, n_markers+step, step):\n",
    "            markers = markers_df[\n",
    "            (markers_df['cluster']==cluster) & (markers_df['tool']==tool) & (markers_df['rank']<=i)\n",
    "        ].gene.unique()\n",
    "            X = adata[mask, markers].X.toarray()\n",
    "            f1 = apply_classifier(X, y_bin)\n",
    "            if tool not in tmp_scores:\n",
    "                tmp_scores[tool] = {}\n",
    "            if cluster not in tmp_scores[tool]:\n",
    "                tmp_scores[tool][cluster] = {}\n",
    "            if 'scores' not in tmp_scores[tool][cluster]:\n",
    "                tmp_scores[tool][cluster]['scores'] = []\n",
    "            tmp_scores[tool][cluster]['scores'].append(f1)\n",
    "        if 'mean' not in tmp_scores[tool][cluster]:\n",
    "            tmp_scores[tool][cluster]['mean'] = []\n",
    "        # mean for each cluster\n",
    "        tmp_scores[tool][cluster]['mean'].append(np.mean(tmp_scores[tool][cluster]['scores']))\n",
    "        print(\"Cluster {} done for tool {}\".format(cluster, tool), file=sys.stderr)\n",
    "        \n",
    "    return tmp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- train with increasing # of features taken from markers rank --------\n",
    "step = 1\n",
    "tools = ['scvi', 'seurat', 'scanpy', 'monocle']\n",
    "n_markers = len(markers_df[markers_df['cluster']==1])\n",
    "import pickle, os\n",
    "if os.path.exists(scores_path):\n",
    "    with open(scores_path, 'rb') as handle:\n",
    "        scores = pickle.load(handle)\n",
    "else:\n",
    "    scores = Parallel(n_jobs=len(tools))(delayed(process)(tool) for tool in tools)\n",
    "    scores2 = {}\n",
    "    for i, el in enumerate(scores):\n",
    "        scores2[list(el.keys())[0]] = el[list(el.keys())[0]]\n",
    "    scores = scores2\n",
    "    for tool in tools:\n",
    "        for i in range(step, n_markers+step, step):\n",
    "            sumForI = 0\n",
    "            for j, cluster in enumerate(clusters):\n",
    "                sumForI += (scores[tool][cluster]['scores'][i-1] * counts[j])\n",
    "            if 'TotalMean' not in scores[tool]:\n",
    "                scores[tool]['TotalMean'] = []\n",
    "            scores[tool]['TotalMean'].append(sumForI/np.sum(counts))\n",
    "    with open(scores_path, 'wb') as handle:\n",
    "        pickle.dump(scores, handle, protocol=pickle.HIGHEST_PROTOCOL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(21, 9))\n",
    "for i, tool in enumerate(tools):\n",
    "    max_i = np.argmax(scores[tool]['TotalMean'])\n",
    "    second_max = np.argsort(scores[tool]['TotalMean'])[-2]\n",
    "    \n",
    "    ax[i//2, i%2].plot([i for i in range(step, n_markers+step, step)], scores[tool]['TotalMean'], marker='o')\n",
    "    \n",
    "    # print max max in red\n",
    "    ax[i//2, i%2].plot([max_i+1], [scores[tool]['TotalMean'][max_i]], marker='o', color='red')\n",
    "    \n",
    "    # print second max in green\n",
    "    ax[i//2, i%2].plot([second_max+1], [scores[tool]['TotalMean'][second_max]], marker='o', color='green')\n",
    "    \n",
    "    # annotation for max\n",
    "    ax[i//2, i%2].annotate('max: {}'.format(round(scores[tool]['TotalMean'][max_i], 3)), xy=(max_i+1, scores[tool]['TotalMean'][max_i]), xytext=(max_i+1, scores[tool]['TotalMean'][max_i]+0.01), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    \n",
    "    # annotation for second max\n",
    "    ax[i//2, i%2].annotate('2nd max: {}'.format(round(scores[tool]['TotalMean'][second_max], 3)), xy=(second_max+1, scores[tool]['TotalMean'][second_max]), xytext=(second_max+1, scores[tool]['TotalMean'][second_max]-0.02), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    ax[i//2, i%2].set_ylabel(\"f1 weighted\")\n",
    "    \n",
    "    # Only last two plots have x label (it's the same for all)\n",
    "    if (i>1):\n",
    "        ax[i//2, i%2].set_xlabel(\"# features\")\n",
    "    # print x tick for max \n",
    "    ax[i//2, i%2].plot([max_i+1, max_i+1], [0.930, scores[tool]['TotalMean'][max_i]], linestyle='--', color='red')\n",
    "    ax[i//2, i%2].plot([second_max+1, second_max+1], [0.930, scores[tool]['TotalMean'][second_max]], linestyle='--', color='green')\n",
    "    ax[i//2, i%2].set_xticks([max_i+1, second_max+1], [max_i+1, second_max+1], minor=True)\n",
    "    # Same scale for all plots\n",
    "    ax[i//2, i%2].set_yticks([round(i, 2) for i in np.arange(0.930, 1, 0.005)])\n",
    "    # Set title\n",
    "    ax[i//2, i%2].set_title(tool)\n",
    "    ax[i//2, i%2].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- train on all features and on markers --------\n",
    "\n",
    "X_all = adata[mask, :].X.toarray()\n",
    "report_all, feature_importance = apply_classifier(X_all, y)\n",
    "report_markers, _ = apply_classifier(adata[mask, markers].X.toarray(), y)\n",
    "\n",
    "pd.DataFrame(report_all).transpose().to_csv(out_path+\"clf_report_all.csv\")\n",
    "pd.DataFrame(report_markers).transpose().to_csv(out_path+\"clf_report_markers.csv\")\n",
    "\n",
    "sorted_idx = (-feature_importance).argsort()\n",
    "rf_features_sorted = adata.var_names[sorted_idx]\n",
    "importaces_sorted = feature_importance[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rf_features_sorted, 'importaces' : importaces_sorted}\n",
    "    ).to_csv(out_path+\"importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- select n_markers*n_clusters features with RFE and RF --------\n",
    "\n",
    "selector = RFE(RandomForestClassifier(), n_features_to_select=n_markers*n_clusters, step=0.5)\n",
    "selector.fit(X_all, y)\n",
    "sorted_idx = (selector.ranking_).argsort()\n",
    "rfe_features_sorted = adata.var_names[sorted_idx]\n",
    "pd.DataFrame(\n",
    "    {'genes' : rfe_features_sorted}\n",
    "    ).to_csv(out_path+\"rfe_ranking.csv\")\n",
    "\n",
    "# automatically choose the number of features\n",
    "# rfe = RFECV(estimator=RandomForestClassifier())\n",
    "# rfe.fit(X_all, y)\n",
    "# rfe.show()\n",
    "\n",
    "# TODO:\n",
    "# - valutare intersezione\n",
    "# - valutare bontà del ranking allenando con markers più in basso nella classifica?\n",
    "\n",
    "# important_features = features_sorted[0:120]\n",
    "# important_features = [f for f, i in zip(features_sorted, importaces_sorted) if i >= importaces_sorted[119]]\n",
    "# intersection = set(markers).intersection(set(important_features))\n",
    "\n",
    "#        rank di randomforest                  rank del tool\n",
    "# gene1         100 *                         * 1 - (0-20)\n",
    "# gene2         1 *                            \n",
    "# gene3         1 *                            \n",
    "# gene4         0 *                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHLPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
